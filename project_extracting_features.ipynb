{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### import kagglehub\n",
    "\n",
    "# Download latest version\n",
    "###path = kagglehub.dataset_download(\"adityajn105/flickr8k\")\n",
    "\n",
    "###print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install tensorflow numpy pandas matplotlib nltk\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# loading dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       image  \\\n",
      "0                      image   \n",
      "1  1000268201_693b08cb0e.jpg   \n",
      "2  1000268201_693b08cb0e.jpg   \n",
      "3  1000268201_693b08cb0e.jpg   \n",
      "4  1000268201_693b08cb0e.jpg   \n",
      "\n",
      "                                             caption  \n",
      "0                                            caption  \n",
      "1  A child in a pink dress is climbing up a set o...  \n",
      "2              A girl going into a wooden building .  \n",
      "3   A little girl climbing into a wooden playhouse .  \n",
      "4  A little girl climbing the stairs to her playh...  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "captions_path = 'captions.txt'\n",
    "captions_data = pd.read_csv(captions_path, delimiter=',', header=None, names=['image', 'caption'])\n",
    "\n",
    "print(captions_data.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# re-arrange the dataset since it could be multiple captions to one image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image ID: image, Captions: ['caption']\n",
      "Image ID: 1000268201_693b08cb0e.jpg, Captions: ['A child in a pink dress is climbing up a set of stairs in an entry way .', 'A girl going into a wooden building .', 'A little girl climbing into a wooden playhouse .', 'A little girl climbing the stairs to her playhouse .', 'A little girl in a pink dress going into a wooden cabin .']\n",
      "Image ID: 1001773457_577c3a7d70.jpg, Captions: ['A black dog and a spotted dog are fighting', 'A black dog and a tri-colored dog playing with each other on the road .', 'A black dog and a white dog with brown spots are staring at each other in the street .', 'Two dogs of different breeds looking at each other on the road .', 'Two dogs on pavement moving toward each other .']\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "image_captions = defaultdict(list)\n",
    "for i, row in captions_data.iterrows():\n",
    "    image_id, caption = row['image'], row['caption']\n",
    "    image_captions[image_id].append(caption)\n",
    "\n",
    "# Example of image ID and corresponding captions\n",
    "for key, value in list(image_captions.items())[:3]:\n",
    "    print(f\"Image ID: {key}, Captions: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split the captions into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training images: 6473, Testing images: 1619\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "# Get unique image IDs\n",
    "unique_image_ids = list(image_captions.keys())\n",
    "\n",
    "# Shuffle and split\n",
    "random.seed(42)\n",
    "random.shuffle(unique_image_ids)\n",
    "split_index = int(len(unique_image_ids) * 0.8)\n",
    "\n",
    "train_image_ids = unique_image_ids[:split_index]\n",
    "test_image_ids = unique_image_ids[split_index:]\n",
    "\n",
    "# Split captions dictionary\n",
    "train_image_captions = {img_id: image_captions[img_id] for img_id in train_image_ids}\n",
    "test_image_captions = {img_id: image_captions[img_id] for img_id in test_image_ids}\n",
    "\n",
    "print(f\"Training images: {len(train_image_captions)}, Testing images: {len(test_image_captions)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import InceptionV3\n",
    "from tensorflow.keras.applications.inception_v3 import preprocess_input\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.models import Model\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels.h5\n",
      "96112376/96112376 [==============================] - 3s 0us/step\n"
     ]
    }
   ],
   "source": [
    "base_model = InceptionV3(weights='imagenet')\n",
    "model = Model(inputs=base_model.input, outputs=base_model.layers[-2].output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Features:  44%|████▍     | 2871/6473 [04:18<04:45, 12.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing image: [Errno 2] No such file or directory: 'Images/image'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Features: 100%|██████████| 6473/6473 [09:59<00:00, 10.80it/s]\n",
      "Extracting Features: 100%|██████████| 1619/1619 [02:54<00:00,  9.29it/s]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "images_directory = 'Images/'\n",
    "from tqdm import tqdm\n",
    "# Extract features for images\n",
    "def extract_features(image_ids, directory):\n",
    "    features = {}\n",
    "    for img_name in tqdm(image_ids, desc=\"Extracting Features\"):\n",
    "        img_path = os.path.join(directory, img_name)\n",
    "        try:\n",
    "            img = load_img(img_path, target_size=(299, 299))\n",
    "            img = img_to_array(img)\n",
    "            img = np.expand_dims(img, axis=0)\n",
    "            img = preprocess_input(img)\n",
    "\n",
    "            feature = model.predict(img, verbose=0)\n",
    "            features[img_name] = feature.flatten()\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {img_name}: {e}\")\n",
    "    return features\n",
    "\n",
    "# Extract features for train and test sets\n",
    "train_image_features = extract_features(train_image_ids, images_directory)\n",
    "test_image_features = extract_features(test_image_ids, images_directory)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
